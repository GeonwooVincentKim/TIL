{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6Xjs2bs7jLxLblykx1f4U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyelinNAM/TIL/blob/master/GAN/0402_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x83wngz72c4t",
        "colab_type": "text"
      },
      "source": [
        "## Generate Fashion MNIST using DCGAN (28x28)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYEReugt2fYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlr4p2l42XFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8beYIcJ2jBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set hyperparameters\n",
        "default_batch_size = 64\n",
        "z_dim = 10 # length of vector z\n",
        "nc = 1 # the number of channel (image; color-3, gray scale-1)\n",
        "g_ch = 64 # the number of featuremap (generator)\n",
        "d_ch = 64 # the number of featuremap (discriminator)\n",
        "lr_D = 0.0002 # learning rate\n",
        "lr_G = 0.0002"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXhmO0uw2k50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator,self).__init__()\n",
        "\n",
        "    self.conv1 = nn.ConvTranspose2d(\n",
        "        in_channels = z_dim,\n",
        "        out_channels = g_ch * 8,\n",
        "        kernel_size = 4,\n",
        "        stride = 1,\n",
        "        padding=0\n",
        "    ) # batch_size * (g_ch*8) * 4 * 4\n",
        "    self.conv1_bn = nn.BatchNorm2d(g_ch*8) \n",
        "    self.conv2 = nn.ConvTranspose2d(g_ch*8,g_ch*4,4,2,1)\n",
        "    self.conv2_bn = nn.BatchNorm2d(g_ch*4)\n",
        "    self.conv3 = nn.ConvTranspose2d(g_ch*4,g_ch*2,4,2,1)\n",
        "    self.conv3_bn = nn.BatchNorm2d(g_ch*2)\n",
        "    self.conv4 = nn.ConvTranspose2d(g_ch*2,g_ch,4,2,1)\n",
        "    self.conv4_bn = nn.BatchNorm2d(g_ch)\n",
        "    self.conv5 = nn.ConvTranspose2d(g_ch,nc,4,2,1)\n",
        "\n",
        "  def weight_init(self,mean,std):\n",
        "    for m in self._modules:\n",
        "      nn.init.normal_(self._modules[m].weight.data,mean,std)\n",
        "\n",
        "  def forward(self,input):\n",
        "    x = F.relu(self.conv1_bn(self.conv1(input)))\n",
        "    x = F.relu(self.conv2_bn(self.conv2(x)))\n",
        "    x = F.relu(self.conv3_bn(self.conv3(x)))\n",
        "    x = F.relu(self.conv4_bn(self.conv4(x)))\n",
        "    x = torch.tanh(self.conv5(x))\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydRkuzxg2lQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator,self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_channels=nc,\n",
        "        out_channels=d_ch,\n",
        "        kernel_size=4,\n",
        "        stride=2,\n",
        "        padding=1\n",
        "    )\n",
        "    self.conv2 = nn.Conv2d(d_ch,d_ch*2,4,2,1)\n",
        "    self.conv2_bn = nn.BatchNorm2d(d_ch*2)\n",
        "    self.conv3 = nn.Conv2d(d_ch*2,d_ch*4,4,2,1)\n",
        "    self.conv3_bn = nn.BatchNorm2d(d_ch*4)\n",
        "    self.conv4= nn.Conv2d(d_ch*4,d_ch*8,4,2,1)\n",
        "    self.conv4_bn = nn.BatchNorm2d(d_ch*8)\n",
        "    self.conv5 = nn.Conv2d(d_ch*8,1,4,1,0)\n",
        "\n",
        "  def weight_init(self,mean,std):\n",
        "    for m in self._modules:\n",
        "      nn.init.normal_(self._modules[m].weight.data,mean,std)\n",
        "\n",
        "  def forward(self,input):\n",
        "    x = F.leaky_relu(self.conv1(input),0.2)\n",
        "    x = F.leaky_relu(self.conv2_bn(self.conv2(x)),0.2)\n",
        "    x = F.leaky_relu(self.conv3_bn(self.conv3(x)),0.2)\n",
        "    x = F.leaky_relu(self.conv4_bn(self.conv4(x)),0.2)\n",
        "    x = torch.sigmoid(self.conv5(x))\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbOCQGwF2mxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = Generator()\n",
        "D = Discriminator()\n",
        "G.weight_init(mean=0.0, std=0.02)\n",
        "D.weight_init(mean=0.0, std=0.02)\n",
        "G.cuda()\n",
        "D.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rViEPDi42ofn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizerD = optim.Adam(D.parameters(), lr=lr_D, betas=(0.5,0.999))\n",
        "optimizerG = optim.Adam(G.parameters(), lr=lr_G, betas=(0.5,0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XYZP6QH2px7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.5,),(0.5,)),\n",
        "])\n",
        "\n",
        "# Download and load the training data\n",
        "train = datasets.FashionMNIST(root='data',download=True,train=True,transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOXGx4Ou2tVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.utils as vutils\n",
        "\n",
        "real_batch = next(iter(trainloader)) # len(iter(trainloader)) = 938 / type(real_batch) > list /len(real_batch)=2 > data, label\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "# real_batch[0].shape > [64,1,64,64]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUHBj4uB2vp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_show(data,epoch):\n",
        "  f = plt.figure(figsize=(10,10))\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(f'{epoch} - image')\n",
        "  plt.imshow(np.transpose(vutils.make_grid(data.to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0))) # 64,1,64,64\n",
        "\n",
        "  f.savefig(f'{epoch}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_zADdtZ2wFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "train_hist={}\n",
        "img_hist = {}\n",
        "\n",
        "train_hist['D_losses'] = []\n",
        "train_hist['G_losses'] = []\n",
        "\n",
        "\n",
        "print('Start Training Loop...')\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "fixed_noise = torch.randn((64,z_dim),device=device).view(-1,z_dim,1,1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  iter_ = 1\n",
        "\n",
        "  D_losses = []\n",
        "  G_losses = []\n",
        "\n",
        "  epoch_start_time = time.time()\n",
        "\n",
        "  for img, label in trainloader: \n",
        "\n",
        "    D.zero_grad()\n",
        "    \n",
        "    img = img.to(device)\n",
        "    batch_size = img.size()[0]\n",
        "    r_label = torch.ones(batch_size).to(device)\n",
        "    f_label = torch.zeros(batch_size).to(device)\n",
        "\n",
        "    noise = torch.randn((batch_size,z_dim),device=device).view(-1,z_dim,1,1)\n",
        "\n",
        "    if (epoch<=5) or (iter_%3==0):\n",
        "\n",
        "      ### 1-1.using Real image ###\n",
        "      D_result = D(img).squeeze() \n",
        "      D_real = criterion(D_result,r_label)\n",
        "      D_real.backward()\n",
        "      Prob_R = D_result.mean().item()\n",
        "\n",
        "      ### 1-2.using Fake image ###\n",
        "      fake = G(noise)\n",
        "      D_result = D(fake.detach()).squeeze()\n",
        "\n",
        "      Prob_F1 = D_result.mean().item()\n",
        "\n",
        "      D_fake = criterion(D_result,f_label)\n",
        "      D_fake.backward()\n",
        "\n",
        "      D_train_loss = D_real + D_fake\n",
        "\n",
        "      optimizerD.step()\n",
        "\n",
        "      train_hist['D_losses'].append(D_train_loss.data)\n",
        "\n",
        "    ### 2.Update G ###\n",
        "\n",
        "    G.zero_grad()\n",
        "\n",
        "    fake = G(noise)\n",
        "    D_result = D(fake).squeeze()\n",
        "\n",
        "    G_train_loss = criterion(D_result,r_label)\n",
        "    G_train_loss.backward()\n",
        "\n",
        "    Prob_F2 = D_result.mean().item()\n",
        "    \n",
        "    optimizerG.step()\n",
        "    \n",
        "    train_hist['G_losses'].append(G_train_loss.data)\n",
        "\n",
        "    if iter_ % 50 == 0:\n",
        "      print(f'[{epoch+1}/{epochs}][{iter_}/{len(trainloader)}]\\tLoss_D:{D_train_loss.data:.3f}\\tLoss_G: {G_train_loss.data:.3f} \\tProb_R: {Prob_R: .3f} \\tProb_F1: {Prob_F1: .3f} \\tProb_F2: {Prob_F2: .3f}')\n",
        "\n",
        "    iter_+=1\n",
        "\n",
        "  epoch_end_time = time.time()\n",
        "  per_epoch_ptime = epoch_end_time - epoch_start_time\n",
        "\n",
        "  fixed_img = G(fixed_noise)\n",
        "  img_hist[epoch] = fixed_img.detach()\n",
        "  img_show(fixed_img.detach().cpu(),epoch+1)\n",
        "  \n",
        "  print(f'[{epoch+1}/{epochs}] -ptime: {per_epoch_ptime:.2f} ')\n",
        "\n",
        "print('finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xtnnQHq2xoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({\n",
        "    'G_state_dict':G.state_dict(),\n",
        "    'D_state_dict':D.state_dict(),\n",
        "    'OpG_state_dict':optimizerG.state_dict(),\n",
        "    'OpD_state_dict':optimizerD.state_dict(),\n",
        "    },'/content/drive/My Drive/model_5)1:3')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}